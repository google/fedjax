{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMfeiEH4O788"
      },
      "source": [
        "# FedJAX Intro\n",
        "\n",
        "[Open In Colab](https://colab.research.google.com/github/google/fedjax/blob/main/notebooks/fedjax_intro.ipynb)\n",
        "\n",
        "This notebook introduces the basic components of FedJAX and walks through:\n",
        "* What is federated learning?\n",
        "* How to run federated simulations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMjinkDX8ZPv"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade -q fedjax==0.0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZGmIRwGOnU6"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import jax\n",
        "import numpy as np\n",
        "\n",
        "import fedjax\n",
        "# We only use TensorFlow for datasets, so we restrict it to CPU only to avoid\n",
        "# issues with certain ops not being available on GPU/TPU.\n",
        "fedjax.training.set_tf_cpu_only()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HyEdeFy1K0X"
      },
      "source": [
        "## What is federated learning?\n",
        "\n",
        "Federated learning (FL) is \"a distributed machine learning approach that trains machine learning models using decentralized examples residing on devices such as smartphones.\"\n",
        "\n",
        "This means that there are two main actors in FL:\n",
        "* Server: Centralized server.\n",
        "* Client: Synonymous with “device”. We use the term “client” from now on.\n",
        "\n",
        "A typical FL algorithm completes the following steps at each training round:\n",
        "1. Server selects a subset of Clients to participate in training.\n",
        "2. Server broadcasts model parameters to the selected Clients.\n",
        "3. Clients complete training on local data.\n",
        "4. Clients send model updates to the Server.\n",
        "5. Server aggregates Client updates into a single update.\n",
        "6. Server uses this aggregation to update the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0FemUmpotUq"
      },
      "source": [
        "## How to write and run federated simulations\n",
        "\n",
        "In this section, we'll describe how to run federated learning simulations. A federated learning simulation typically consists of the following components:\n",
        "* Federated dataset: a list of client ids and a dataset for each client id.\n",
        "* Model and parameters\n",
        "* Optimizers for updating the model parameters\n",
        "* Federated algorithm: defines how to train across clients and aggregate multiple client outputs into a single server output\n",
        "\n",
        "We will use the [Federated EMNIST-62](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/emnist/load_data) image recognition task and train our model using the [Federated Averaging](https://arxiv.org/pdf/1602.05629.pdf) algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG1nKEkoqSe8"
      },
      "source": [
        "### Loading the dataset\n",
        "\n",
        "For EMNIST, the examples are grouped by writer source where each writer is treated as a separate client. For more details, see https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/emnist/load_data.\n",
        "\n",
        "FedJAX reuses the already well-defined and supported [`tff.simulation.datasets.ClientData`](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/ClientData) construct introduced by TensorFlow Federated (TFF). There are quite a few functionalities baked in to `tff.simulation.datasets.ClientData`, but for the most part, we only use `client_ids` and `create_tf_dataset_for_client`.\n",
        "\n",
        "For convenience, we provide `fedjax.datasets.emnist.load_data` as well as other canonical federated datasets under `fedjax.datasets`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVDaQsOGynDD"
      },
      "outputs": [],
      "source": [
        "# Load the train and test federated datasets for MNIST (digits only).\n",
        "federated_train, federated_test = fedjax.datasets.emnist.load_data(\n",
        "    only_digits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 170,
          "status": "ok",
          "timestamp": 1616028576242,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "mD0sYfzhqGZ6",
        "outputId": "67c87fbb-704f-46fd-98e2-166a9bbad403"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_client_ids = 3383\n",
            "client_id = f0000_14\n",
            "client_dataset = OrderedDict([('x', TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(), dtype=tf.int32, name=None))])\n"
          ]
        }
      ],
      "source": [
        "# Federated dataset consists of client ids and a dataset for each client id.\n",
        "# There are 3383 clients in the MNIST federated dataset.\n",
        "print(f'num_client_ids = {len(federated_train.client_ids)}')\n",
        "\n",
        "# Let's look at the dataset for one of the clients.\n",
        "client_id = federated_train.client_ids[0]\n",
        "client_dataset = federated_train.create_tf_dataset_for_client(client_id)\n",
        "print(f'client_id = {client_id}')\n",
        "\n",
        "# client_dataset is a tf.data.Dataset and element_spec just shows up the\n",
        "# expected structure (name, shape, type) of each element in the dataset.\n",
        "# In most cases, x is the input and y is the label.\n",
        "print(f'client_dataset = {client_dataset.element_spec}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRRSFQh1yqWM"
      },
      "source": [
        "The `client_dataset` almost always contains elements of the following structure\n",
        "\n",
        "```\n",
        "{\n",
        "  'x': features,\n",
        "  'y': labels\n",
        "}\n",
        "```\n",
        "\n",
        "we refer to this structure as a `Batch`.\n",
        "\n",
        "The output client dataset is a `tf.data.Dataset` of `tf.Tensor`. However, in order to use these examples with JAX, we'll need to convert this to NumPy arrays. Fortunately, TensorFlow provides `tf.data.Dataset.as_numpy_iterator()` which does exactly what we want and converts a `tf.data.Dataset` to an itertor of NumPy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "height": 299
        },
        "executionInfo": {
          "elapsed": 1442,
          "status": "ok",
          "timestamp": 1616028585705,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "PmRSaXZEq3e5",
        "outputId": "2308c39d-e02c-4050-915f-32b2eb9929d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u003cmatplotlib.image.AxesImage at 0x7f07e1940630\u003e"
            ]
          },
          "execution_count": 4,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\nbGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsT\nAAALEwEAmpwYAAANTklEQVR4nO3dfaxk9V3H8fcHWJZkqZEVwZUHoQ1tSowFcoON+IBBG0pieNBq\nUck2wWwTS6SxRkk1KX9oJI1t1aStbgWhBGnBgqAhbQlpQhsNcEGExaVCkdKFza4NNgWjyz58/eMe\nyAXuzL07c+Zh9/d+JZM5c36/M+e7s/vZc+Y8zC9VhaTD3xGzLkDSdBh2qRGGXWqEYZcaYdilRhh2\nqRGG/TCS5MYkf9xN/0ySb65xuTX31aHLsB+mqurrVfWOUfomeTbJL/RdU5JNSe5O8kKSSnJa3+vQ\nYIZd03QA+DLwy7MupEWG/RCW5OwkjyR5KckXgWOWtZ2fZMey1+ck+deu7+1Jvrhsl/+1vkluBk4F\n/jHJy0l+v696q2pXVX0GeKiv99TaGfZDVJKjgX8AbgY2ArczYIvZ9b0TuLHreytw6Up9q+oK4Dng\nl6rq2Kr6+Arvd2qS7w15/Pr4f0L17ahZF6CRvRtYB/x5Ld3g8PdJfndI36OAv+z63pHkwVFXXFXP\nAT846vKaDbfsh64fBZ6v19/J9O2D6PudiVWmuWTYD107gZOSZNm8Uw+i7ylD3nvorZDdbvzLQx6/\nsbY/gqbJsB+6/gXYB/xOkqOSXAacO6TvfuCqru/FQ/oC7ALeOqixqp7rvs8PetwyaNkkxwDru5fr\nu9eaAsN+iKqqV4DLgA8A/w38GnDHKn2vBL4H/CbwT8CeAW//p8AfdQfbfq/XwuF/gZe76Se715qC\n+OMVbUryAPBXVfW3s65F0+GWvRFJfi7Jj3S78ZuBn2DpAhc1wlNv7XgHcBtwLPAt4FeqaudsS9I0\nuRsvNcLdeKkRU92NPzrr6xg2THOVUlP+j//hldqTldrGCnuSC4G/AI4E/qaqrhvW/xg28JO5YJxV\nShrigbpvYNvIu/FJjgQ+DbwXOBO4PMmZo76fpMka5zv7ucDTVfVMd9HGF4CL+ylLUt/GCftJvP5m\nih3dvNdJsiXJYpLFvQMv2JI0aeOEfaWDAG86j1dVW6tqoaoW1r12SbSkaRsn7Dt4/Z1TJwMvjFeO\npEkZJ+wPAWckOb37JZT3A3f3U5akvo186q2q9iW5CvgKS6febqiqJ3qrTFKvxjrPXlX3APf0VIuk\nCfJyWakRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGX\nGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1q\nxFhDNid5FngJ2A/sq6qFPoqS1L+xwt75+ar6bg/vI2mC3I2XGjFu2Av4apKHk2xZqUOSLUkWkyzu\nZc+Yq5M0qnF348+rqheSnADcm+TJqrp/eYeq2gpsBfiBbKwx1ydpRGNt2avqhe55N3AncG4fRUnq\n38hhT7IhyVtenQbeA2zrqzBJ/RpnN/5E4M4kr77P31XVl3upSlLvRg57VT0DvKvHWiRNkKfepEYY\ndqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHYpUYYdqkRhl1qhGGXGmHY\npUYYdqkRhl1qhGGXGmHYpUb0MbCjDmdHHDm8/cD+6dShsblllxph2KVGGHapEYZdaoRhlxph2KVG\nGHapEZ5nb93SkNuDeR79sLHqlj3JDUl2J9m2bN7GJPcmeap7Pm6yZUoa11p2428ELnzDvGuA+6rq\nDOC+7rWkObZq2KvqfuDFN8y+GLipm74JuKTfsiT1bdQDdCdW1U6A7vmEQR2TbEmymGRxL3tGXJ2k\ncU38aHxVba2qhapaWMf6Sa9O0gCjhn1Xkk0A3fPu/kqSNAmjhv1uYHM3vRm4q59yJE3KqufZk9wK\nnA8cn2QH8DHgOuC2JFcCzwHvm2SRGl2OGv5XXPv2DW3/z1vfNbR9w9c3DG0/4TP/PLBt3Np0cFYN\ne1VdPqDpgp5rkTRBXi4rNcKwS40w7FIjDLvUCMMuNcJbXA8HQ25TrQM1dNGjTj5paPtXfurTQ9t/\n+09+a2j7gSFttd/bZ6fJLbvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS43wPPthIEetG9hWe18Zuuz2\na04e2v74KwN/cQyAA9ueHNo+7DZWb2GdLrfsUiMMu9QIwy41wrBLjTDsUiMMu9QIwy41wvPsh4Ij\njhzaXPv2Dmw78p1nDF32mcv+emj7eVd/cGj7sXlwaLvmh1t2qRGGXWqEYZcaYdilRhh2qRGGXWqE\nYZca4Xn2Q0COGPy78AC1b/Bvw59z6/D7zU+/Z/jvvr/99geGtjvs8qFj1S17khuS7E6ybdm8a5M8\nn+TR7nHRZMuUNK617MbfCFy4wvxPVdVZ3eOefsuS1LdVw15V9wMvTqEWSRM0zgG6q5I81u3mHzeo\nU5ItSRaTLO5lzxirkzSOUcP+WeBtwFnATuATgzpW1daqWqiqhXWsH3F1ksY1UtiraldV7a+qA8Dn\ngHP7LUtS30YKe5JNy15eCmwb1FfSfFj1PHuSW4HzgeOT7AA+Bpyf5CyggGeB4Tc9ayzjnKt+aMtZ\nQ9vf/uDi8DdY9V56z6MfKlYNe1VdvsLs6ydQi6QJ8nJZqRGGXWqEYZcaYdilRhh2qRHe4nq4e/Dx\n4e0ZfvssB/b3V4tmyi271AjDLjXCsEuNMOxSIwy71AjDLjXCsEuN8Dz74W6VW1Q9j94Ot+xSIwy7\n1AjDLjXCsEuNMOxSIwy71AjDLjXC8+yHO8+jq+OWXWqEYZcaYdilRhh2qRGGXWqEYZcaYdilRqwa\n9iSnJPlaku1JnkhydTd/Y5J7kzzVPR83+XIljWotW/Z9wEeq6p3Au4EPJTkTuAa4r6rOAO7rXkua\nU6uGvap2VtUj3fRLwHbgJOBi4Kau203AJROqUVIPDuo7e5LTgLOBB4ATq2onLP2HAJzQe3WSerPm\nsCc5FvgS8OGq+v5BLLclyWKSxb3sGaVGST1YU9iTrGMp6LdU1R3d7F1JNnXtm4DdKy1bVVuraqGq\nFtaxvo+aJY1gLUfjA1wPbK+qTy5ruhvY3E1vBu7qvzxJfVnLLa7nAVcAjyd5tJv3UeA64LYkVwLP\nAe+bSIWSerFq2KvqG8CgQbwv6LccSZPiFXRSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxS\nIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuNMOxSIwy71AjDLjXCsEuN\nMOxSIwy71AjDLjXCsEuNMOxSIwy71IhVw57klCRfS7I9yRNJru7mX5vk+SSPdo+LJl+upFGtOj47\nsA/4SFU9kuQtwMNJ7u3aPlVVfza58iT1ZdWwV9VOYGc3/VKS7cBJky5MUr8O6jt7ktOAs4EHullX\nJXksyQ1JjhuwzJYki0kW97JnvGoljWzNYU9yLPAl4MNV9X3gs8DbgLNY2vJ/YqXlqmprVS1U1cI6\n1o9fsaSRrCnsSdaxFPRbquoOgKraVVX7q+oA8Dng3MmVKWlcazkaH+B6YHtVfXLZ/E3Lul0KbOu/\nPEl9WcvR+POAK4DHkzzazfsocHmSs4ACngU+OIH6JPVkLUfjvwFkhaZ7+i9H0qR4BZ3UCMMuNcKw\nS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNcKwS40w7FIjDLvUCMMuNSJVNb2VJf8FfHvZrOOB\n706tgIMzr7XNa11gbaPqs7Yfq6ofXqlhqmF/08qTxapamFkBQ8xrbfNaF1jbqKZVm7vxUiMMu9SI\nWYd964zXP8y81javdYG1jWoqtc30O7uk6Zn1ll3SlBh2qREzCXuSC5N8M8nTSa6ZRQ2DJHk2yePd\nMNSLM67lhiS7k2xbNm9jknuTPNU9rzjG3oxqm4thvIcMMz7Tz27Ww59P/Tt7kiOB/wB+EdgBPARc\nXlX/PtVCBkjyLLBQVTO/ACPJzwIvA5+vqh/v5n0ceLGqruv+ozyuqv5gTmq7Fnh51sN4d6MVbVo+\nzDhwCfABZvjZDanrV5nC5zaLLfu5wNNV9UxVvQJ8Abh4BnXMvaq6H3jxDbMvBm7qpm9i6R/L1A2o\nbS5U1c6qeqSbfgl4dZjxmX52Q+qailmE/STgO8te72C+xnsv4KtJHk6yZdbFrODEqtoJS/94gBNm\nXM8brTqM9zS9YZjxufnsRhn+fFyzCPtKQ0nN0/m/86rqHOC9wIe63VWtzZqG8Z6WFYYZnwujDn8+\nrlmEfQdwyrLXJwMvzKCOFVXVC93zbuBO5m8o6l2vjqDbPe+ecT2vmadhvFcaZpw5+OxmOfz5LML+\nEHBGktOTHA28H7h7BnW8SZIN3YETkmwA3sP8DUV9N7C5m94M3DXDWl5nXobxHjTMODP+7GY+/HlV\nTf0BXMTSEflvAX84ixoG1PVW4N+6xxOzrg24laXdur0s7RFdCfwQcB/wVPe8cY5quxl4HHiMpWBt\nmlFtP83SV8PHgEe7x0Wz/uyG1DWVz83LZaVGeAWd1AjDLjXCsEuNMOxSIwy71AjDLjXCsEuN+H8R\n1jXF3YQnCAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "\u003cFigure size 600x400 with 1 Axes\u003e"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# We use as_numpy_iterator to convert the tf.data.Dataset to an iterator of\n",
        "# numpy arrays for use with JAX.\n",
        "examples = list(client_dataset.as_numpy_iterator())\n",
        "\n",
        "# For MNIST there are 10 possible labels (digits).\n",
        "digits = '0123456789'\n",
        "\n",
        "# x is the pixels for the image and y is the label index.\n",
        "x = examples[0]['x']\n",
        "y = examples[0]['y']\n",
        "\n",
        "# Here, we plot what the input pixels (x) looks like and what the true label is.\n",
        "plt.title(f'digit = {digits[y]}')\n",
        "# The pixels are flattened but we reshape back to 2D for viewing.\n",
        "plt.imshow(x.reshape(28, 28))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF9VXOzEqO--"
      },
      "source": [
        "### Defining the model\n",
        "\n",
        "In this section, we will cover how to intialize models suitable for use in FedJAX. Rather than reimplement core model components (layers, etc.), FedJAX uses a flexible structure that is implementation agnostic and works with multiple popular JAX neural network libraries (such as [Haiku](https://github.com/deepmind/dm-haiku) and [stax](https://jax.readthedocs.io/en/latest/jax.experimental.stax.html)).\n",
        "\n",
        "Similar to datasets, we provide a list of canonical models under `fedjax.models`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zBNIYxZyvZx"
      },
      "outputs": [],
      "source": [
        "# Create a multi-layer fully connected neural network for MNIST.\n",
        "model = fedjax.models.emnist.create_dense_model(\n",
        "    only_digits=True, hidden_units=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1podbEYyynQ"
      },
      "source": [
        "Now, we have a common `fedjax.Model` that can work with later FedJAX functions and utilities. This model has a couple of core methods:\n",
        "\n",
        "* `init_params`: Initializes model parameters.\n",
        "* `backward_pass`: Returns gradients w.r.t. model parameters as well as a few other outputs such as loss and scalar batch weight (typically batch size).\n",
        "* `evaluate`: Runs model forward pass and evaluates output predictions.\n",
        "\n",
        "Because JAX is designed to be functional, there are no stateful functions meaning APIs usually follow the pattern of \n",
        "\n",
        "```\n",
        "# Initialize some state\n",
        "state = init()\n",
        "# Take some input state, and return a new, updated output state.\n",
        "state = apply(state)\n",
        "```\n",
        "\n",
        "The same pattern applies for `fedjax.Model` where the input/output is the model parameters (i.e. trainable weights)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 170,
          "status": "ok",
          "timestamp": 1616028611354,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "fcNhQtHTzWCx",
        "outputId": "8eb8d0f5-9baf-4e6a-9ffd-ea10837756ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FlatMapping({\n",
            "  'linear': FlatMapping({'b': (100,), 'w': (784, 100)}),\n",
            "  'linear_1': FlatMapping({'b': (100,), 'w': (100, 100)}),\n",
            "  'linear_2': FlatMapping({'b': (10,), 'w': (100, 10)}),\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# Initialize model parameters using a pseudo random number generator (PRNG).\n",
        "# PRNG generated sequences are not truly random but are actually determined by\n",
        "# an initial value, typically referred to as the `seed`.\n",
        "# https://jax.readthedocs.io/en/latest/jax-101/05-random-numbers.html?highlight=random\n",
        "rng = jax.random.PRNGKey(seed=0)\n",
        "params = model.init_params(rng)\n",
        "\n",
        "# View the structure of the parameters.\n",
        "# jax.tree_util contains functions useful for working with PyTrees\n",
        "# https://jax.readthedocs.io/en/latest/pytrees.html\n",
        "print(jax.tree_util.tree_map(lambda l: l.shape, params))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZUAls8_zh8Z"
      },
      "source": [
        "Now, we define an example dummy batch input to pass into the model to see what the outputs of `backward_pass` looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 567,
          "status": "ok",
          "timestamp": 1616028626340,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "FRP65PFqy4ji",
        "outputId": "1425c697-aa2b-4de3-8f27-76b2fc7e1241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "grads structure = FlatMapping({\n",
            "  'linear': FlatMapping({'b': (100,), 'w': (784, 100)}),\n",
            "  'linear_1': FlatMapping({'b': (100,), 'w': (100, 100)}),\n",
            "  'linear_2': FlatMapping({'b': (10,), 'w': (100, 10)}),\n",
            "})\n",
            "num_examples = 8.0\n"
          ]
        }
      ],
      "source": [
        "# Example batch input for EMNIST-62 where the leading axis is batch size.\n",
        "batch_size = 8\n",
        "example_batch = {\n",
        "    'x': np.ones((batch_size, 28, 28, 1)),\n",
        "    'y': np.ones((batch_size))\n",
        "}\n",
        "\n",
        "backward_pass_output = model.backward_pass(params, example_batch, rng)\n",
        "# backward_pass_output contains gradients along with some additional info like\n",
        "# the number of examples in the input batch.\n",
        "grads = backward_pass_output.grads\n",
        "num_examples = backward_pass_output.num_examples\n",
        "\n",
        "# Note that grads follows the exact same structure of params. This is expected\n",
        "# since grads is intended to be used to update the weights in params.\n",
        "print(f'grads structure = {jax.tree_util.tree_map(lambda l: l.shape, grads)}')\n",
        "# As expected, num_examples is batch_size.\n",
        "print(f'num_examples = {num_examples}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vurEoXy-y-tD"
      },
      "source": [
        "Now we can use the same example dummy batch input to view the output of `evaluate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 428,
          "status": "ok",
          "timestamp": 1616028629373,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "9zHryVBuy_HP",
        "outputId": "272e569e-19f4-4e8f-ba62-b9c3b2c3f2ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "metrics[loss] = 2.264116\n",
            "metrics[accuracy] = 0.0\n"
          ]
        }
      ],
      "source": [
        "# evaluate produces a dictionary of metric names to metric values.\n",
        "metrics = model.evaluate(params, example_batch)\n",
        "\n",
        "print('metrics[loss] =', metrics['loss'].result())\n",
        "print('metrics[accuracy] =', metrics['accuracy'].result())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqPR3IN6zCKB"
      },
      "source": [
        "### Optimizers\n",
        "\n",
        "By default, FedJAX comes packaged with common optimizers like: SGD, Adam, Adagrad, etc. These optimizers are implemented and provided by [optax](https://github.com/deepmind/optax) but we wrap them in a common container (similar to what we do with Model) for use in FedJAX.\n",
        "\n",
        "Below is an typical example usage of `fedjax.Optimizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 1902,
          "status": "ok",
          "timestamp": 1616028633312,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "qpqxXlGnzD0Y",
        "outputId": "ecf33f02-b132-430c-fdc3-198676b7b2e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "opt_state = [ScaleByAdamState(count=(), mu=FlatMapping({\n",
            "  'linear': FlatMapping({'b': (100,), 'w': (784, 100)}),\n",
            "  'linear_1': FlatMapping({'b': (100,), 'w': (100, 100)}),\n",
            "  'linear_2': FlatMapping({'b': (10,), 'w': (100, 10)}),\n",
            "}), nu=FlatMapping({\n",
            "  'linear': FlatMapping({'b': (100,), 'w': (784, 100)}),\n",
            "  'linear_1': FlatMapping({'b': (100,), 'w': (100, 100)}),\n",
            "  'linear_2': FlatMapping({'b': (10,), 'w': (100, 10)}),\n",
            "})), ScaleState()]\n",
            "updates = FlatMapping({\n",
            "  'linear': FlatMapping({'b': (100,), 'w': (784, 100)}),\n",
            "  'linear_1': FlatMapping({'b': (100,), 'w': (100, 100)}),\n",
            "  'linear_2': FlatMapping({'b': (10,), 'w': (100, 10)}),\n",
            "})\n",
            "params = FlatMapping({\n",
            "  'linear': FlatMapping({'b': (100,), 'w': (784, 100)}),\n",
            "  'linear_1': FlatMapping({'b': (100,), 'w': (100, 100)}),\n",
            "  'linear_2': FlatMapping({'b': (10,), 'w': (100, 10)}),\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "optimizer = fedjax.get_optimizer(fedjax.OptimizerName.ADAM, learning_rate=0.1)\n",
        "\n",
        "# Initialize optimizer state using model parameters\n",
        "opt_state = optimizer.init_fn(params)\n",
        "print(f'opt_state = {jax.tree_util.tree_map(lambda l: l.shape, opt_state)}')\n",
        "\n",
        "# Produce parameter updates using gradients and optimizer state.\n",
        "updates, opt_state = optimizer.update_fn(grads, opt_state)\n",
        "print(f'updates = {jax.tree_util.tree_map(lambda l: l.shape, updates)}')\n",
        "\n",
        "# Apply updates to parameters.\n",
        "params = optimizer.apply_updates(params, updates)\n",
        "print(f'params = {jax.tree_util.tree_map(lambda l: l.shape, params)}')\n",
        "\n",
        "# updates, grads, and params have identical structures but opt_state can contain\n",
        "# additional statistics that are used in optimizers like Adam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVOTv-II18GY"
      },
      "source": [
        "### Federated algorithm\n",
        "\n",
        "Now that we've defined the federated data and the model, we can move on to actually running the federated algorithm. Almost all federated algorithms consist of two functions.\n",
        "* `init_state`: Initializes federated algorithm server state\n",
        "* `run_one_round`: Runs one round of federated training\n",
        "\n",
        "Below, we'll implement [Federated Averaging (FedAvg)](https://arxiv.org/abs/1602.05629) as these two functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDpjtJYc2T_D"
      },
      "outputs": [],
      "source": [
        "# Setup like initializing our dataset, model, and optimizers.\n",
        "federated_train, federated_test = fedjax.datasets.emnist.load_data(\n",
        "    only_digits=True)\n",
        "\n",
        "model = fedjax.models.emnist.create_dense_model(\n",
        "    only_digits=True, hidden_units=100)\n",
        "\n",
        "# client_optimizer used in local client updates is SGD.\n",
        "client_optimizer = fedjax.get_optimizer(\n",
        "    fedjax.OptimizerName.SGD, learning_rate=0.1)\n",
        "# server_optimizer used to update server model parameters from round to round\n",
        "# is SGD with momentum.\n",
        "server_optimizer = fedjax.get_optimizer(\n",
        "    fedjax.OptimizerName.MOMENTUM, learning_rate=1.0, momentum=0.9)\n",
        "\n",
        "# Generator of PRNGKeys.\n",
        "rng_seq = fedjax.PRNGSequence(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFl-6qCczJPi"
      },
      "source": [
        "Below is the pseudocode for FedAvg from the original paper:\n",
        "\n",
        "```\n",
        "Algorithm 1 FederatedAveraging.\n",
        "The K clients are indexed by k; B is the local minibatch size,\n",
        "E is the number of local epochs, and η is the learning rate.\n",
        "\n",
        "Server executes:\n",
        "  initialize w_0\n",
        "  for each round t = 1, 2, . . . do\n",
        "    m ← max(C · K, 1)\n",
        "    St ← (random set of m clients)\n",
        "    for each client k ∈ St in parallel do\n",
        "      wk_t+1 ← ClientUpdate(k, w_t)\n",
        "    w_t+1 ← sum_k=1_K((nk/n) * wk_t+1)\n",
        "\n",
        "ClientUpdate(k, w): // Run on client k\n",
        "  wk ← w\n",
        "  B ← (split Pk into batches of size B)\n",
        "  for each local epoch i from 1 to E do\n",
        "    for batch b ∈ B do\n",
        "      wk ← wk − η∇l(wk; b)\n",
        "  return w - wk to server\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 14564,
          "status": "ok",
          "timestamp": 1616028657459,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 240
        },
        "id": "SsmOUggfGBuW",
        "outputId": "e5ccb1cf-0d86-4c0b-a603-7905ba11878f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round_num = 0\n",
            "loss = 2.2629027366638184 accuracy = 0.1345454603433609\n",
            "round_num = 1\n",
            "loss = 2.200199604034424 accuracy = 0.10181818157434464\n",
            "round_num = 2\n",
            "loss = 2.1171212196350098 accuracy = 0.10545454919338226\n",
            "round_num = 3\n",
            "loss = 2.0372910499572754 accuracy = 0.16727273166179657\n",
            "round_num = 4\n",
            "loss = 1.5442819595336914 accuracy = 0.4036363661289215\n",
            "round_num = 5\n",
            "loss = 1.1109448671340942 accuracy = 0.614545464515686\n",
            "round_num = 6\n",
            "loss = 0.7976325154304504 accuracy = 0.7054545283317566\n",
            "round_num = 7\n",
            "loss = 0.4819725453853607 accuracy = 0.8472727537155151\n",
            "round_num = 8\n",
            "loss = 0.35074591636657715 accuracy = 0.9127272963523865\n",
            "round_num = 9\n",
            "loss = 0.36465850472450256 accuracy = 0.9018182158470154\n"
          ]
        }
      ],
      "source": [
        "# Initialize server state.\n",
        "FedAvgServerState = collections.namedtuple(\n",
        "    'FedAvgServerState', ['server_params', 'server_opt_state'])\n",
        "\n",
        "server_params = model.init_params(next(rng_seq))\n",
        "server_opt_state = server_optimizer.init_fn(server_params)\n",
        "server_state = FedAvgServerState(server_params, server_opt_state)\n",
        "\n",
        "\n",
        "def client_update(server_state, client_data):\n",
        "  \"\"\"Updates parameters on local client data.\"\"\"\n",
        "  client_params = server_state.server_params\n",
        "  client_opt_state = client_optimizer.init_fn(client_params)\n",
        "  num_examples = 0.\n",
        "\n",
        "  for batch in client_data:\n",
        "    # Update parameters on mini-batch.\n",
        "    backward_pass_output = model.backward_pass(\n",
        "        client_params, batch, next(rng_seq))\n",
        "    grads = backward_pass_output.grads\n",
        "    updates, client_opt_state = client_optimizer.update_fn(\n",
        "        grads, client_opt_state)\n",
        "    client_params = client_optimizer.apply_updates(client_params, updates)\n",
        "    # Keep track of total number of examples seen.\n",
        "    num_examples += backward_pass_output.num_examples\n",
        "\n",
        "  # Send the model update \n",
        "  delta_params = jax.tree_util.tree_multimap(\n",
        "      lambda a, b: a - b, server_state.server_params, client_params)\n",
        "  return delta_params, num_examples\n",
        "\n",
        "\n",
        "def server_update(server_state, client_updates):\n",
        "  \"\"\"Updates server state using client updates.\"\"\"\n",
        "  # Weighted average of client_updates.\n",
        "  server_grads = fedjax.tree_mean(client_updates)\n",
        "  # Update server parameters and optimizer state.\n",
        "  updates, server_opt_state = server_optimizer.update_fn(\n",
        "      server_grads, server_state.server_opt_state)\n",
        "  server_params = server_optimizer.apply_updates(\n",
        "      server_state.server_params, updates)\n",
        "  return FedAvgServerState(server_params, server_opt_state)\n",
        "\n",
        "\n",
        "def evaluate(server_state, client_datas):\n",
        "  datas = [d for cd in client_datas for d in cd]\n",
        "  return fedjax.evaluate_single_client(datas, model, server_state.server_params)\n",
        "\n",
        "\n",
        "# Run multiple federated training rounds.\n",
        "for round_num in range(10):\n",
        "  # Sample some subset of clients per training round and read their datasets.\n",
        "  client_ids = federated_train.client_ids[:3]\n",
        "  client_datas = []\n",
        "  for client_id in client_ids:\n",
        "    tf_dataset = (federated_train.create_tf_dataset_for_client(client_id)\n",
        "                  .batch(8))\n",
        "    client_datas.append(list(tf_dataset.as_numpy_iterator()))\n",
        "\n",
        "  # Run one round of training.\n",
        "  client_updates = []\n",
        "  # Run client_update on sampled clients.\n",
        "  for client_data in client_datas:\n",
        "    client_updates.append(client_update(server_state, client_data))\n",
        "\n",
        "  # Update server_state using client_updates.\n",
        "  server_state = server_update(server_state, client_updates)\n",
        "\n",
        "  # Run some evaluation to make sure training is happening properly.\n",
        "  metrics = evaluate(server_state, client_datas)\n",
        "  print(f'round_num = {round_num}')\n",
        "  print(f'loss = {metrics[\"loss\"]} accuracy = {metrics[\"accuracy\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7l_A-rJzM1H"
      },
      "source": [
        "We implemented FedAvg this way in the colab to closely match the pseudocode for clarity and readability. For a faster version, see the implementation inside the library for `fedjax.algorithms.FedAvg`."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "fedjax_intro.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
